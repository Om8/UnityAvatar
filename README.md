# Volume AI Unity Avatar
This projects aim is to make it easy to connect NLP systems to a virtual avatar in Unity 3D. It uses a mixture of Watson, Azure and Windows to input voice, generate a suitable response and output a neural voice that is synced up to a mesh. 

The project uses Unity Events to connect the modules, allowing for different solutions to be plugged and unplugged. There is currently Watson and Windows voice input and Watson and Azure voice out, alternatives are available. The whole system works by passing strings around, it is possible to connect an external dialogue tree with just strings in and strings out. 
## Images/GIFs
![alt text](https://i.imgur.com/ax8RdRd.png)  

![alt text](https://i.imgur.com/IQ2NR5s.gif)
![alt text](https://i.imgur.com/KuSIvuf.gif)

## Usage
The main use for this project is a tool for Volume to experiment with implementing their AI with a virtual character that can be edited and adjusted easily. These characters can then be displayed on screens or in VR. 

## More Info
To find out more about how to use and adjust this project, check out the [wiki](https://github.com/Om8/VolumeAIUnityAvatar/wiki)
